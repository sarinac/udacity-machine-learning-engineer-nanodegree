{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "train = pd.read_csv(\"data/train.csv\")\n",
    "test = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "train_y = train[\"label\"]\n",
    "train_X = train.drop(columns=[\"label\"]).to_numpy()\n",
    "test_y = test[\"label\"]\n",
    "test_X = test.drop(columns=[\"label\"]).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store model scores\n",
    "models = {\n",
    "    \"Model\": [],\n",
    "    \"Train Accuracy\": [],\n",
    "    \"Train F1\": [],\n",
    "    \"Train Precision\": [],\n",
    "    \"Train Recall\": [],\n",
    "    \"Test Accuracy\": [],\n",
    "    \"Test F1\": [],\n",
    "    \"Test Precision\": [],\n",
    "    \"Test Recall\": [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_scores(accuracy, f1, precision, recall):\n",
    "    \"\"\"Print accuracy, f1, precision, and recall.\"\"\"\n",
    "    print(\"Accuracy: {}%\".format(accuracy))\n",
    "    print(\"F1: {}%\".format(f1))\n",
    "    print(\"Precision: {}%\".format(precision))\n",
    "    print(\"Recall: {}%\".format(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(true_y, pred_y):\n",
    "    \"\"\"Get accuracy, f1, precision, and recall.\"\"\"\n",
    "    accuracy = round(100 * accuracy_score(true_y, pred_y), 1)\n",
    "    precision = round(100 * precision_score(true_y, pred_y), 1)\n",
    "    recall = round(100 * recall_score(true_y, pred_y), 1)\n",
    "    f1 = round(100 * f1_score(true_y, pred_y), 1)\n",
    "    \n",
    "    return (accuracy, f1, precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_no_cv(model_name, model, train_X, train_y, test_X, test_y):\n",
    "    \"\"\"Run model and add scores to models dict.\"\"\"\n",
    "    \n",
    "    # Fit model\n",
    "    model.fit(train_X, train_y)\n",
    "    \n",
    "    # Predict with train dataset\n",
    "    pred_train_y = model.predict(train_X)\n",
    "    \n",
    "    # Predict with test dataset\n",
    "    pred_test_y = model.predict(test_X)\n",
    "    \n",
    "    # Record model\n",
    "    models[\"Model\"].append(model_name)\n",
    "    \n",
    "    # Record train scores\n",
    "    accuracy, f1, precision, recall = get_scores(train_y, pred_train_y)\n",
    "    models[\"Train Accuracy\"].append(accuracy)\n",
    "    models[\"Train F1\"].append(f1)\n",
    "    models[\"Train Precision\"].append(precision)\n",
    "    models[\"Train Recall\"].append(recall)\n",
    "    \n",
    "    # Record test scores\n",
    "    accuracy, f1, precision, recall = get_scores(test_y, pred_test_y)\n",
    "    models[\"Test Accuracy\"].append(accuracy)\n",
    "    models[\"Test F1\"].append(f1)\n",
    "    models[\"Test Precision\"].append(precision)\n",
    "    models[\"Test Recall\"].append(recall)\n",
    "    \n",
    "    # Print test scores\n",
    "    print_scores(accuracy, f1, precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model_name, model, train_X, train_y, test_X, test_y):\n",
    "    \"\"\"Run model and add scores to models dict.\"\"\"\n",
    "    \n",
    "    # Specify scorings for the cross validation\n",
    "    scoring = {\n",
    "        \"accuracy\": make_scorer(accuracy_score), \n",
    "        \"f1\": make_scorer(f1_score),\n",
    "        \"precision\": make_scorer(precision_score),\n",
    "        \"recall\": make_scorer(recall_score), \n",
    "    }\n",
    "    \n",
    "    # Fit model with CV (to record train scores with CV)\n",
    "    cv_results = cross_validate(model, train_X, train_y, cv=5, scoring=scoring)\n",
    "\n",
    "    # Fit model\n",
    "    model.fit(train_X, train_y)\n",
    "    \n",
    "    # Predict with test dataset\n",
    "    pred_test_y = model.predict(test_X)\n",
    "    \n",
    "    # Record model\n",
    "    models[\"Model\"].append(model_name)\n",
    "    \n",
    "    # Record train scores\n",
    "    models[\"Train Accuracy\"].append(round(100*cv_results[\"test_accuracy\"].mean(), 1))\n",
    "    models[\"Train F1\"].append(round(100*cv_results[\"test_f1\"].mean(), 1))\n",
    "    models[\"Train Precision\"].append(round(100*cv_results[\"test_precision\"].mean(), 1))\n",
    "    models[\"Train Recall\"].append(round(100*cv_results[\"test_recall\"].mean(), 1))\n",
    "    \n",
    "    # Record test scores\n",
    "    accuracy, f1, precision, recall = get_scores(test_y, pred_test_y)\n",
    "    models[\"Test Accuracy\"].append(accuracy)\n",
    "    models[\"Test F1\"].append(f1)\n",
    "    models[\"Test Precision\"].append(precision)\n",
    "    models[\"Test Recall\"].append(recall)\n",
    "    \n",
    "    # Print test scores\n",
    "    print_scores(accuracy, f1, precision, recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 66.9%\n",
      "F1: 36.7%\n",
      "Precision: 56.9%\n",
      "Recall: 27.1%\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "run_model_no_cv(\"KNN (no cross validation)\", knn, train_X, train_y, test_X, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The benchmark model performs rather poorly with 67% accuracy but 37% F1 score. \n",
    "\n",
    "The precision is 57%. In other words, the model is only capturing 57% of the true population that would respond to the given offers. \n",
    "\n",
    "The recall of 27% is very low, which means that the model is assuming that customers won't respond to certain offers when they actually would have. Ideally, the recall should be high if the marketing campaign wanted to reach more people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Train F1</th>\n",
       "      <th>Train Precision</th>\n",
       "      <th>Train Recall</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Test F1</th>\n",
       "      <th>Test Precision</th>\n",
       "      <th>Test Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN (no cross validation)</td>\n",
       "      <td>82.1</td>\n",
       "      <td>66.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>49.5</td>\n",
       "      <td>66.9</td>\n",
       "      <td>36.7</td>\n",
       "      <td>56.9</td>\n",
       "      <td>27.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model  Train Accuracy  Train F1  Train Precision  \\\n",
       "0  KNN (no cross validation)            82.1      66.2            100.0   \n",
       "\n",
       "   Train Recall  Test Accuracy  Test F1  Test Precision  Test Recall  \n",
       "0          49.5           66.9     36.7            56.9         27.1  "
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing that the train dataset performs significantly better than the test dataset, the model is clearly overfitting. Cross-validation should help inform which model fits best with less overfitting. After choosing a type of model, tuning with regularization hyperparameters should help decrease overfitting even more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 66.9%\n",
      "F1: 36.7%\n",
      "Precision: 56.9%\n",
      "Recall: 27.1%\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "run_model(\"KNN\", knn, train_X, train_y, test_X, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit and test different types of models without tuning to see how they tend to perform. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC, SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarinachen/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/sarinachen/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/sarinachen/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/sarinachen/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/sarinachen/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 66.5%\n",
      "F1: 34.8%\n",
      "Precision: 56.2%\n",
      "Recall: 25.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarinachen/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "svc = LinearSVC(random_state=42)\n",
    "run_model(\"Linear SVC\", svc, train_X, train_y, test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 71.3%\n",
      "F1: 49.0%\n",
      "Precision: 66.4%\n",
      "Recall: 38.8%\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(random_state=42)\n",
    "run_model(\"SVC (RGB)\", svc, train_X, train_y, test_X, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 66.4%\n",
      "F1: 36.1%\n",
      "Precision: 55.5%\n",
      "Recall: 26.7%\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=42)\n",
    "run_model(\"Logistic Regression\", lr, train_X, train_y, test_X, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 64.5%\n",
      "F1: 50.3%\n",
      "Precision: 50.0%\n",
      "Recall: 50.7%\n"
     ]
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier(random_state=42)\n",
    "run_model(\"Decision Tree\", dtc, train_X, train_y, test_X, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 70.5%\n",
      "F1: 54.0%\n",
      "Precision: 60.5%\n",
      "Recall: 48.8%\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(random_state=42)\n",
    "run_model(\"Random Forest\", rfc, train_X, train_y, test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 72.1%\n",
      "F1: 52.1%\n",
      "Precision: 66.7%\n",
      "Recall: 42.8%\n"
     ]
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier(random_state=42)\n",
    "run_model(\"Gradient Boosting\", gbc, train_X, train_y, test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Train F1</th>\n",
       "      <th>Train Precision</th>\n",
       "      <th>Train Recall</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Test F1</th>\n",
       "      <th>Test Precision</th>\n",
       "      <th>Test Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN (no cross validation)</td>\n",
       "      <td>82.100000</td>\n",
       "      <td>66.200000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>49.500000</td>\n",
       "      <td>66.9</td>\n",
       "      <td>36.7</td>\n",
       "      <td>56.9</td>\n",
       "      <td>27.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.673029</td>\n",
       "      <td>0.375939</td>\n",
       "      <td>0.581462</td>\n",
       "      <td>0.277836</td>\n",
       "      <td>66.9</td>\n",
       "      <td>36.7</td>\n",
       "      <td>56.9</td>\n",
       "      <td>27.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>0.666574</td>\n",
       "      <td>0.355790</td>\n",
       "      <td>0.565735</td>\n",
       "      <td>0.259840</td>\n",
       "      <td>66.5</td>\n",
       "      <td>34.8</td>\n",
       "      <td>56.2</td>\n",
       "      <td>25.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC (RGB)</td>\n",
       "      <td>0.713606</td>\n",
       "      <td>0.488128</td>\n",
       "      <td>0.666302</td>\n",
       "      <td>0.385182</td>\n",
       "      <td>71.3</td>\n",
       "      <td>49.0</td>\n",
       "      <td>66.4</td>\n",
       "      <td>38.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.665156</td>\n",
       "      <td>0.366474</td>\n",
       "      <td>0.557353</td>\n",
       "      <td>0.273311</td>\n",
       "      <td>66.4</td>\n",
       "      <td>36.1</td>\n",
       "      <td>55.5</td>\n",
       "      <td>26.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decission Tree</td>\n",
       "      <td>0.633067</td>\n",
       "      <td>0.489620</td>\n",
       "      <td>0.482989</td>\n",
       "      <td>0.496474</td>\n",
       "      <td>64.5</td>\n",
       "      <td>50.3</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.697431</td>\n",
       "      <td>0.527090</td>\n",
       "      <td>0.591099</td>\n",
       "      <td>0.475637</td>\n",
       "      <td>70.5</td>\n",
       "      <td>54.0</td>\n",
       "      <td>60.5</td>\n",
       "      <td>48.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.717916</td>\n",
       "      <td>0.512961</td>\n",
       "      <td>0.661523</td>\n",
       "      <td>0.419071</td>\n",
       "      <td>72.1</td>\n",
       "      <td>52.1</td>\n",
       "      <td>66.7</td>\n",
       "      <td>42.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model  Train Accuracy   Train F1  Train Precision  \\\n",
       "0  KNN (no cross validation)       82.100000  66.200000       100.000000   \n",
       "1                        KNN        0.673029   0.375939         0.581462   \n",
       "2                 Linear SVC        0.666574   0.355790         0.565735   \n",
       "3                  SVC (RGB)        0.713606   0.488128         0.666302   \n",
       "4        Logistic Regression        0.665156   0.366474         0.557353   \n",
       "5             Decission Tree        0.633067   0.489620         0.482989   \n",
       "6              Random Forest        0.697431   0.527090         0.591099   \n",
       "7          Gradient Boosting        0.717916   0.512961         0.661523   \n",
       "\n",
       "   Train Recall  Test Accuracy  Test F1  Test Precision  Test Recall  \n",
       "0     49.500000           66.9     36.7            56.9         27.1  \n",
       "1      0.277836           66.9     36.7            56.9         27.1  \n",
       "2      0.259840           66.5     34.8            56.2         25.2  \n",
       "3      0.385182           71.3     49.0            66.4         38.8  \n",
       "4      0.273311           66.4     36.1            55.5         26.7  \n",
       "5      0.496474           64.5     50.3            50.0         50.7  \n",
       "6      0.475637           70.5     54.0            60.5         48.8  \n",
       "7      0.419071           72.1     52.1            66.7         42.8  "
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See fitting results and how well they score against test data\n",
    "pd.DataFrame(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model KNN shows that the model overfits and requires cross-validation to reflect a more realistic score. With cross-validation in the subsequent, the training scores reflect test scores better. Later on, some ways of handling overfitting include adding more data (which we don't have), reducing the number of features, and using regularization.\n",
    "\n",
    "Out of the 7 types of models, the 2 ensemble models perform the best, with **Gradient Boosting** slightly better than **Random Forest**.\n",
    "\n",
    "**Decision Tree** and **Support Vector Classifier** also have better F1 scores than the benchmark model.\n",
    "\n",
    "For tuning models, I will pick 2 models to experiment with. Even though the last 2 models performed the best, I am choosing to tune the Gradient Boosting Classifier and Support Vector Classifier, which are 2 different types of models (as opposed to both ensemble models)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  20 | elapsed:  7.6min remaining:  7.6min\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  20 | elapsed:  8.6min remaining:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:  9.3min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:  9.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'gamma': 1}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=SVC()\n",
    "\n",
    "# Larger C (more punishment on penalty) => overfit, Larger gamma => overfit \n",
    "param_grid = {\"C\": [1, .01], \"gamma\": [10, 1]}\n",
    "\n",
    "kfold = KFold(n_splits=5)\n",
    "grid_search = GridSearchCV(model, param_grid, cv=kfold, scoring='f1', n_jobs=-1, verbose=5)\n",
    "grid_search.fit(train_X, train_y)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  1.4min\n",
      "/Users/sarinachen/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  45 | elapsed:  9.5min remaining:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed: 10.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'gamma': 1}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=SVC()\n",
    "\n",
    "# Larger C (more punishment on penalty) => overfit, Larger gamma => overfit \n",
    "param_grid = {\"C\": [1, .01, .001], \"gamma\": [1, .1, .01]}\n",
    "\n",
    "kfold = KFold(n_splits=5)\n",
    "grid_search = GridSearchCV(model, param_grid, cv=kfold, scoring='f1', n_jobs=-1, verbose=5)\n",
    "grid_search.fit(train_X, train_y)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>177.368824</td>\n",
       "      <td>24.821479</td>\n",
       "      <td>11.326293</td>\n",
       "      <td>0.134378</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 1, 'gamma': 1}</td>\n",
       "      <td>0.504933</td>\n",
       "      <td>0.513110</td>\n",
       "      <td>0.507564</td>\n",
       "      <td>0.512926</td>\n",
       "      <td>0.502144</td>\n",
       "      <td>0.508135</td>\n",
       "      <td>0.004340</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76.787069</td>\n",
       "      <td>3.001430</td>\n",
       "      <td>9.986992</td>\n",
       "      <td>0.367901</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 1, 'gamma': 0.1}</td>\n",
       "      <td>0.491205</td>\n",
       "      <td>0.495310</td>\n",
       "      <td>0.502667</td>\n",
       "      <td>0.488616</td>\n",
       "      <td>0.489627</td>\n",
       "      <td>0.493485</td>\n",
       "      <td>0.005127</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>74.275015</td>\n",
       "      <td>2.803524</td>\n",
       "      <td>11.466666</td>\n",
       "      <td>0.588392</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 1, 'gamma': 0.01}</td>\n",
       "      <td>0.363671</td>\n",
       "      <td>0.352019</td>\n",
       "      <td>0.368379</td>\n",
       "      <td>0.362165</td>\n",
       "      <td>0.329775</td>\n",
       "      <td>0.355202</td>\n",
       "      <td>0.013788</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85.826534</td>\n",
       "      <td>3.007520</td>\n",
       "      <td>12.623096</td>\n",
       "      <td>0.246241</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.01, 'gamma': 0.1}</td>\n",
       "      <td>0.257322</td>\n",
       "      <td>0.249947</td>\n",
       "      <td>0.266696</td>\n",
       "      <td>0.258934</td>\n",
       "      <td>0.226053</td>\n",
       "      <td>0.251790</td>\n",
       "      <td>0.013926</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89.364387</td>\n",
       "      <td>2.085711</td>\n",
       "      <td>12.780059</td>\n",
       "      <td>0.241913</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 0.01, 'gamma': 1}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001049</td>\n",
       "      <td>0.000539</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>84.387152</td>\n",
       "      <td>1.531406</td>\n",
       "      <td>12.641575</td>\n",
       "      <td>0.282472</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 0.01, 'gamma': 0.01}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>82.336634</td>\n",
       "      <td>3.530188</td>\n",
       "      <td>13.279525</td>\n",
       "      <td>0.422779</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 0.001, 'gamma': 1}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>89.430690</td>\n",
       "      <td>1.781649</td>\n",
       "      <td>12.681464</td>\n",
       "      <td>0.441327</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.1}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>65.989669</td>\n",
       "      <td>18.905263</td>\n",
       "      <td>8.015471</td>\n",
       "      <td>2.359072</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.01}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0     177.368824     24.821479        11.326293        0.134378       1   \n",
       "1      76.787069      3.001430         9.986992        0.367901       1   \n",
       "2      74.275015      2.803524        11.466666        0.588392       1   \n",
       "4      85.826534      3.007520        12.623096        0.246241    0.01   \n",
       "3      89.364387      2.085711        12.780059        0.241913    0.01   \n",
       "5      84.387152      1.531406        12.641575        0.282472    0.01   \n",
       "6      82.336634      3.530188        13.279525        0.422779   0.001   \n",
       "7      89.430690      1.781649        12.681464        0.441327   0.001   \n",
       "8      65.989669     18.905263         8.015471        2.359072   0.001   \n",
       "\n",
       "  param_gamma                       params  split0_test_score  \\\n",
       "0           1         {'C': 1, 'gamma': 1}           0.504933   \n",
       "1         0.1       {'C': 1, 'gamma': 0.1}           0.491205   \n",
       "2        0.01      {'C': 1, 'gamma': 0.01}           0.363671   \n",
       "4         0.1    {'C': 0.01, 'gamma': 0.1}           0.257322   \n",
       "3           1      {'C': 0.01, 'gamma': 1}           0.000000   \n",
       "5        0.01   {'C': 0.01, 'gamma': 0.01}           0.000000   \n",
       "6           1     {'C': 0.001, 'gamma': 1}           0.000000   \n",
       "7         0.1   {'C': 0.001, 'gamma': 0.1}           0.000000   \n",
       "8        0.01  {'C': 0.001, 'gamma': 0.01}           0.000000   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.513110           0.507564           0.512926           0.502144   \n",
       "1           0.495310           0.502667           0.488616           0.489627   \n",
       "2           0.352019           0.368379           0.362165           0.329775   \n",
       "4           0.249947           0.266696           0.258934           0.226053   \n",
       "3           0.001049           0.000539           0.000000           0.000520   \n",
       "5           0.000000           0.000000           0.000000           0.000000   \n",
       "6           0.000000           0.000000           0.000000           0.000000   \n",
       "7           0.000000           0.000000           0.000000           0.000000   \n",
       "8           0.000000           0.000000           0.000000           0.000000   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.508135        0.004340                1  \n",
       "1         0.493485        0.005127                2  \n",
       "2         0.355202        0.013788                3  \n",
       "4         0.251790        0.013926                4  \n",
       "3         0.000422        0.000393                5  \n",
       "5         0.000000        0.000000                6  \n",
       "6         0.000000        0.000000                6  \n",
       "7         0.000000        0.000000                6  \n",
       "8         0.000000        0.000000                6  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_search.cv_results_).sort_values(by=\"rank_test_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  20 | elapsed:  3.4min remaining:  3.4min\n",
      "/Users/sarinachen/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  20 | elapsed:  4.2min remaining:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:  5.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:  5.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'gamma': 1}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try removing some features\n",
    "train_X2 = train.drop(columns=[\"label\", \"prior_number_transactions\", \"prior_received\", \"prior_spend_amt\"]).to_numpy()\n",
    "\n",
    "model=SVC()\n",
    "\n",
    "param_grid = {\"C\": [1, .03], \"gamma\": [1, .3]}\n",
    "\n",
    "kfold = KFold(n_splits=5)\n",
    "grid_search2 = GridSearchCV(model, param_grid, cv=kfold, scoring='f1', n_jobs=-1, verbose=5)\n",
    "grid_search2.fit(train_X2, train_y)\n",
    "grid_search2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>132.186267</td>\n",
       "      <td>10.150113</td>\n",
       "      <td>9.589521</td>\n",
       "      <td>0.279560</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 1, 'gamma': 1}</td>\n",
       "      <td>0.510182</td>\n",
       "      <td>0.518135</td>\n",
       "      <td>0.527368</td>\n",
       "      <td>0.507078</td>\n",
       "      <td>0.517662</td>\n",
       "      <td>0.516085</td>\n",
       "      <td>0.007071</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98.506275</td>\n",
       "      <td>11.147708</td>\n",
       "      <td>8.866189</td>\n",
       "      <td>0.556816</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'C': 1, 'gamma': 0.3}</td>\n",
       "      <td>0.508947</td>\n",
       "      <td>0.510207</td>\n",
       "      <td>0.514629</td>\n",
       "      <td>0.500815</td>\n",
       "      <td>0.505692</td>\n",
       "      <td>0.508058</td>\n",
       "      <td>0.004619</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79.376194</td>\n",
       "      <td>8.879311</td>\n",
       "      <td>10.860957</td>\n",
       "      <td>9.801024</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'C': 0.03, 'gamma': 0.3}</td>\n",
       "      <td>0.409302</td>\n",
       "      <td>0.423732</td>\n",
       "      <td>0.412171</td>\n",
       "      <td>0.411225</td>\n",
       "      <td>0.394450</td>\n",
       "      <td>0.410176</td>\n",
       "      <td>0.009348</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86.790714</td>\n",
       "      <td>7.930210</td>\n",
       "      <td>10.428060</td>\n",
       "      <td>0.600005</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 0.03, 'gamma': 1}</td>\n",
       "      <td>0.323752</td>\n",
       "      <td>0.329454</td>\n",
       "      <td>0.338063</td>\n",
       "      <td>0.326122</td>\n",
       "      <td>0.318209</td>\n",
       "      <td>0.327120</td>\n",
       "      <td>0.006587</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0     132.186267     10.150113         9.589521        0.279560       1   \n",
       "1      98.506275     11.147708         8.866189        0.556816       1   \n",
       "3      79.376194      8.879311        10.860957        9.801024    0.03   \n",
       "2      86.790714      7.930210        10.428060        0.600005    0.03   \n",
       "\n",
       "  param_gamma                     params  split0_test_score  \\\n",
       "0           1       {'C': 1, 'gamma': 1}           0.510182   \n",
       "1         0.3     {'C': 1, 'gamma': 0.3}           0.508947   \n",
       "3         0.3  {'C': 0.03, 'gamma': 0.3}           0.409302   \n",
       "2           1    {'C': 0.03, 'gamma': 1}           0.323752   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.518135           0.527368           0.507078           0.517662   \n",
       "1           0.510207           0.514629           0.500815           0.505692   \n",
       "3           0.423732           0.412171           0.411225           0.394450   \n",
       "2           0.329454           0.338063           0.326122           0.318209   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.516085        0.007071                1  \n",
       "1         0.508058        0.004619                2  \n",
       "3         0.410176        0.009348                3  \n",
       "2         0.327120        0.006587                4  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_search2.cv_results_).sort_values(by=\"rank_test_score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default parameters that control regularization had the highest F1 scores. Dropping a few columns helped increase the F1 score by 0.8%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  45 | elapsed:  1.8min remaining:   13.6s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 12, 'min_samples_split': 50}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=GradientBoostingClassifier()\n",
    "\n",
    "param_grid = {\"min_samples_split\": [10, 30, 50], \"max_depth\": [5, 12, 15]}\n",
    "kfold = KFold(n_splits=5)\n",
    "grid_search3 = GridSearchCV(model, param_grid, cv=kfold, scoring='f1', n_jobs=-1, verbose=5)\n",
    "grid_search3.fit(train_X, train_y)\n",
    "grid_search3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20.098824</td>\n",
       "      <td>0.049391</td>\n",
       "      <td>0.062520</td>\n",
       "      <td>0.001213</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 12, 'min_samples_split': 50}</td>\n",
       "      <td>0.546163</td>\n",
       "      <td>0.548548</td>\n",
       "      <td>0.554812</td>\n",
       "      <td>0.539172</td>\n",
       "      <td>0.538360</td>\n",
       "      <td>0.545411</td>\n",
       "      <td>0.006123</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.807984</td>\n",
       "      <td>0.585802</td>\n",
       "      <td>0.064796</td>\n",
       "      <td>0.002469</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>{'max_depth': 12, 'min_samples_split': 30}</td>\n",
       "      <td>0.537694</td>\n",
       "      <td>0.542586</td>\n",
       "      <td>0.546156</td>\n",
       "      <td>0.536845</td>\n",
       "      <td>0.540012</td>\n",
       "      <td>0.540658</td>\n",
       "      <td>0.003397</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.810423</td>\n",
       "      <td>0.087306</td>\n",
       "      <td>0.067371</td>\n",
       "      <td>0.001512</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 12, 'min_samples_split': 10}</td>\n",
       "      <td>0.537579</td>\n",
       "      <td>0.542575</td>\n",
       "      <td>0.549853</td>\n",
       "      <td>0.533058</td>\n",
       "      <td>0.537681</td>\n",
       "      <td>0.540149</td>\n",
       "      <td>0.005710</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.572885</td>\n",
       "      <td>0.049406</td>\n",
       "      <td>0.027670</td>\n",
       "      <td>0.001799</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 50}</td>\n",
       "      <td>0.543292</td>\n",
       "      <td>0.537129</td>\n",
       "      <td>0.549640</td>\n",
       "      <td>0.538084</td>\n",
       "      <td>0.527225</td>\n",
       "      <td>0.539074</td>\n",
       "      <td>0.007411</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23.044359</td>\n",
       "      <td>0.595383</td>\n",
       "      <td>0.066992</td>\n",
       "      <td>0.008306</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 50}</td>\n",
       "      <td>0.537203</td>\n",
       "      <td>0.537993</td>\n",
       "      <td>0.551291</td>\n",
       "      <td>0.533020</td>\n",
       "      <td>0.534267</td>\n",
       "      <td>0.538755</td>\n",
       "      <td>0.006530</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.638596</td>\n",
       "      <td>0.021887</td>\n",
       "      <td>0.029923</td>\n",
       "      <td>0.006975</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 30}</td>\n",
       "      <td>0.540696</td>\n",
       "      <td>0.537189</td>\n",
       "      <td>0.548220</td>\n",
       "      <td>0.539281</td>\n",
       "      <td>0.527902</td>\n",
       "      <td>0.538657</td>\n",
       "      <td>0.006540</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.657738</td>\n",
       "      <td>0.023658</td>\n",
       "      <td>0.028774</td>\n",
       "      <td>0.002550</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 10}</td>\n",
       "      <td>0.539970</td>\n",
       "      <td>0.538438</td>\n",
       "      <td>0.551930</td>\n",
       "      <td>0.536555</td>\n",
       "      <td>0.525813</td>\n",
       "      <td>0.538541</td>\n",
       "      <td>0.008334</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>26.311870</td>\n",
       "      <td>0.523468</td>\n",
       "      <td>0.088328</td>\n",
       "      <td>0.002192</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 30}</td>\n",
       "      <td>0.539007</td>\n",
       "      <td>0.536368</td>\n",
       "      <td>0.542525</td>\n",
       "      <td>0.536064</td>\n",
       "      <td>0.537588</td>\n",
       "      <td>0.538310</td>\n",
       "      <td>0.002349</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31.531116</td>\n",
       "      <td>0.390477</td>\n",
       "      <td>0.101321</td>\n",
       "      <td>0.001540</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 10}</td>\n",
       "      <td>0.533615</td>\n",
       "      <td>0.532094</td>\n",
       "      <td>0.542861</td>\n",
       "      <td>0.528933</td>\n",
       "      <td>0.533104</td>\n",
       "      <td>0.534121</td>\n",
       "      <td>0.004663</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "5      20.098824      0.049391         0.062520        0.001213   \n",
       "4      19.807984      0.585802         0.064796        0.002469   \n",
       "3      20.810423      0.087306         0.067371        0.001512   \n",
       "2       8.572885      0.049406         0.027670        0.001799   \n",
       "8      23.044359      0.595383         0.066992        0.008306   \n",
       "1       8.638596      0.021887         0.029923        0.006975   \n",
       "0       8.657738      0.023658         0.028774        0.002550   \n",
       "7      26.311870      0.523468         0.088328        0.002192   \n",
       "6      31.531116      0.390477         0.101321        0.001540   \n",
       "\n",
       "  param_max_depth param_min_samples_split  \\\n",
       "5              12                      50   \n",
       "4              12                      30   \n",
       "3              12                      10   \n",
       "2               5                      50   \n",
       "8              15                      50   \n",
       "1               5                      30   \n",
       "0               5                      10   \n",
       "7              15                      30   \n",
       "6              15                      10   \n",
       "\n",
       "                                       params  split0_test_score  \\\n",
       "5  {'max_depth': 12, 'min_samples_split': 50}           0.546163   \n",
       "4  {'max_depth': 12, 'min_samples_split': 30}           0.537694   \n",
       "3  {'max_depth': 12, 'min_samples_split': 10}           0.537579   \n",
       "2   {'max_depth': 5, 'min_samples_split': 50}           0.543292   \n",
       "8  {'max_depth': 15, 'min_samples_split': 50}           0.537203   \n",
       "1   {'max_depth': 5, 'min_samples_split': 30}           0.540696   \n",
       "0   {'max_depth': 5, 'min_samples_split': 10}           0.539970   \n",
       "7  {'max_depth': 15, 'min_samples_split': 30}           0.539007   \n",
       "6  {'max_depth': 15, 'min_samples_split': 10}           0.533615   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "5           0.548548           0.554812           0.539172           0.538360   \n",
       "4           0.542586           0.546156           0.536845           0.540012   \n",
       "3           0.542575           0.549853           0.533058           0.537681   \n",
       "2           0.537129           0.549640           0.538084           0.527225   \n",
       "8           0.537993           0.551291           0.533020           0.534267   \n",
       "1           0.537189           0.548220           0.539281           0.527902   \n",
       "0           0.538438           0.551930           0.536555           0.525813   \n",
       "7           0.536368           0.542525           0.536064           0.537588   \n",
       "6           0.532094           0.542861           0.528933           0.533104   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "5         0.545411        0.006123                1  \n",
       "4         0.540658        0.003397                2  \n",
       "3         0.540149        0.005710                3  \n",
       "2         0.539074        0.007411                4  \n",
       "8         0.538755        0.006530                5  \n",
       "1         0.538657        0.006540                6  \n",
       "0         0.538541        0.008334                7  \n",
       "7         0.538310        0.002349                8  \n",
       "6         0.534121        0.004663                9  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_search3.cv_results_).sort_values(by=\"rank_test_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  45 | elapsed:  1.5min remaining:   11.6s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 12, 'min_samples_split': 50}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=GradientBoostingClassifier()\n",
    "\n",
    "param_grid = {\"min_samples_split\": [10, 30, 50], \"max_depth\": [5, 12, 15]}\n",
    "kfold = KFold(n_splits=5)\n",
    "grid_search4 = GridSearchCV(model, param_grid, cv=kfold, scoring='f1', n_jobs=-1, verbose=5)\n",
    "grid_search4.fit(train_X2, train_y)\n",
    "grid_search4.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17.508952</td>\n",
       "      <td>0.058941</td>\n",
       "      <td>0.060660</td>\n",
       "      <td>0.003279</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 12, 'min_samples_split': 50}</td>\n",
       "      <td>0.539417</td>\n",
       "      <td>0.541325</td>\n",
       "      <td>0.550625</td>\n",
       "      <td>0.530375</td>\n",
       "      <td>0.543723</td>\n",
       "      <td>0.541093</td>\n",
       "      <td>0.006565</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.148139</td>\n",
       "      <td>0.549761</td>\n",
       "      <td>0.060748</td>\n",
       "      <td>0.004966</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>{'max_depth': 12, 'min_samples_split': 30}</td>\n",
       "      <td>0.539528</td>\n",
       "      <td>0.543681</td>\n",
       "      <td>0.548712</td>\n",
       "      <td>0.528447</td>\n",
       "      <td>0.537174</td>\n",
       "      <td>0.539508</td>\n",
       "      <td>0.006781</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.019256</td>\n",
       "      <td>0.112273</td>\n",
       "      <td>0.065301</td>\n",
       "      <td>0.003366</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 12, 'min_samples_split': 10}</td>\n",
       "      <td>0.538451</td>\n",
       "      <td>0.542441</td>\n",
       "      <td>0.545428</td>\n",
       "      <td>0.520714</td>\n",
       "      <td>0.544696</td>\n",
       "      <td>0.538346</td>\n",
       "      <td>0.009145</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20.027388</td>\n",
       "      <td>0.496115</td>\n",
       "      <td>0.062320</td>\n",
       "      <td>0.007043</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 50}</td>\n",
       "      <td>0.534907</td>\n",
       "      <td>0.540728</td>\n",
       "      <td>0.541039</td>\n",
       "      <td>0.524633</td>\n",
       "      <td>0.532894</td>\n",
       "      <td>0.534840</td>\n",
       "      <td>0.006018</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22.762008</td>\n",
       "      <td>0.492581</td>\n",
       "      <td>0.082310</td>\n",
       "      <td>0.001757</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 30}</td>\n",
       "      <td>0.534475</td>\n",
       "      <td>0.534327</td>\n",
       "      <td>0.534734</td>\n",
       "      <td>0.522423</td>\n",
       "      <td>0.530971</td>\n",
       "      <td>0.531386</td>\n",
       "      <td>0.004689</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.478611</td>\n",
       "      <td>0.241330</td>\n",
       "      <td>0.026346</td>\n",
       "      <td>0.002109</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 30}</td>\n",
       "      <td>0.530619</td>\n",
       "      <td>0.533042</td>\n",
       "      <td>0.542109</td>\n",
       "      <td>0.523373</td>\n",
       "      <td>0.524524</td>\n",
       "      <td>0.530733</td>\n",
       "      <td>0.006745</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>27.222423</td>\n",
       "      <td>0.276596</td>\n",
       "      <td>0.095333</td>\n",
       "      <td>0.002435</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 10}</td>\n",
       "      <td>0.533775</td>\n",
       "      <td>0.531764</td>\n",
       "      <td>0.535107</td>\n",
       "      <td>0.514649</td>\n",
       "      <td>0.527420</td>\n",
       "      <td>0.528543</td>\n",
       "      <td>0.007418</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.180994</td>\n",
       "      <td>0.036198</td>\n",
       "      <td>0.025585</td>\n",
       "      <td>0.002862</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 50}</td>\n",
       "      <td>0.529854</td>\n",
       "      <td>0.533727</td>\n",
       "      <td>0.537772</td>\n",
       "      <td>0.515480</td>\n",
       "      <td>0.522632</td>\n",
       "      <td>0.527893</td>\n",
       "      <td>0.007965</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.628521</td>\n",
       "      <td>0.052347</td>\n",
       "      <td>0.028549</td>\n",
       "      <td>0.003426</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 10}</td>\n",
       "      <td>0.529801</td>\n",
       "      <td>0.530312</td>\n",
       "      <td>0.539344</td>\n",
       "      <td>0.518061</td>\n",
       "      <td>0.520075</td>\n",
       "      <td>0.527519</td>\n",
       "      <td>0.007716</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "5      17.508952      0.058941         0.060660        0.003279   \n",
       "4      17.148139      0.549761         0.060748        0.004966   \n",
       "3      18.019256      0.112273         0.065301        0.003366   \n",
       "8      20.027388      0.496115         0.062320        0.007043   \n",
       "7      22.762008      0.492581         0.082310        0.001757   \n",
       "1       7.478611      0.241330         0.026346        0.002109   \n",
       "6      27.222423      0.276596         0.095333        0.002435   \n",
       "2       7.180994      0.036198         0.025585        0.002862   \n",
       "0       7.628521      0.052347         0.028549        0.003426   \n",
       "\n",
       "  param_max_depth param_min_samples_split  \\\n",
       "5              12                      50   \n",
       "4              12                      30   \n",
       "3              12                      10   \n",
       "8              15                      50   \n",
       "7              15                      30   \n",
       "1               5                      30   \n",
       "6              15                      10   \n",
       "2               5                      50   \n",
       "0               5                      10   \n",
       "\n",
       "                                       params  split0_test_score  \\\n",
       "5  {'max_depth': 12, 'min_samples_split': 50}           0.539417   \n",
       "4  {'max_depth': 12, 'min_samples_split': 30}           0.539528   \n",
       "3  {'max_depth': 12, 'min_samples_split': 10}           0.538451   \n",
       "8  {'max_depth': 15, 'min_samples_split': 50}           0.534907   \n",
       "7  {'max_depth': 15, 'min_samples_split': 30}           0.534475   \n",
       "1   {'max_depth': 5, 'min_samples_split': 30}           0.530619   \n",
       "6  {'max_depth': 15, 'min_samples_split': 10}           0.533775   \n",
       "2   {'max_depth': 5, 'min_samples_split': 50}           0.529854   \n",
       "0   {'max_depth': 5, 'min_samples_split': 10}           0.529801   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "5           0.541325           0.550625           0.530375           0.543723   \n",
       "4           0.543681           0.548712           0.528447           0.537174   \n",
       "3           0.542441           0.545428           0.520714           0.544696   \n",
       "8           0.540728           0.541039           0.524633           0.532894   \n",
       "7           0.534327           0.534734           0.522423           0.530971   \n",
       "1           0.533042           0.542109           0.523373           0.524524   \n",
       "6           0.531764           0.535107           0.514649           0.527420   \n",
       "2           0.533727           0.537772           0.515480           0.522632   \n",
       "0           0.530312           0.539344           0.518061           0.520075   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "5         0.541093        0.006565                1  \n",
       "4         0.539508        0.006781                2  \n",
       "3         0.538346        0.009145                3  \n",
       "8         0.534840        0.006018                4  \n",
       "7         0.531386        0.004689                5  \n",
       "1         0.530733        0.006745                6  \n",
       "6         0.528543        0.007418                7  \n",
       "2         0.527893        0.007965                8  \n",
       "0         0.527519        0.007716                9  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_search4.cv_results_).sort_values(by=\"rank_test_score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best performing model is the Gradient Boosting Classifier with the tree-specific hyperparameters of `max_depth=12` and `min_samples_split=50`. The F1 score is 54%, which is better than the original 52% without tuning. Using the entire test dataset features was only 0.4% better than dropping 3 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 72.5%\n",
      "F1: 56.5%\n",
      "Precision: 64.4%\n",
      "Recall: 50.2%\n"
     ]
    }
   ],
   "source": [
    "model=GradientBoostingClassifier(random_state=42, **{'max_depth': 12, 'min_samples_split': 50})\n",
    "model.fit(train_X, train_y)\n",
    "\n",
    "run_model(\"Gradient Boosting (tuned)\", model, train_X, train_y, test_X, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We achieved higher scores than the benchmark and untuned model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=[8,4])\n",
    "fig.suptitle(\"Feature Importance\")\n",
    "\n",
    "ax.bar(range(len(model.feature_importances_)), model.feature_importances_)\n",
    "plt.xticks(rotation=90)\n",
    "ax.set_xticks(np.arange(len(train.columns[1:])))\n",
    "ax.set_xticklabels(train.columns[1:])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fe3a1013850>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(model, test_X, test_y)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
